{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_processing.subject_selectors import *\n",
    "from data_processing.window_splitters import *\n",
    "from data_processing.train_test_spliters import *\n",
    "import pathlib\n",
    "from os.path import join, isfile\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from models.imputer import WindowedImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "subjectSelector: SubjectSelector = SubjectSelectorList(join(pathlib.Path().resolve(), \"data\\\\me_time_fused\\\\subjects\"), ['1', '2'], True, True)\n",
    "subjects = subjectSelector.get_subjects()\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSplitter: WindowSplitter = WindowSplitterNoOverlap(720, [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax], [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax])\n",
    "windowedData: dict[str, DataFrame] = windowSplitter.split(subjects)\n",
    "windowedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = TrainTestSplitterOutlierPersons(1, 0.8).split(windowedData)\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "# print(len(windowedData['121'][\"steps_nanmin\"] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = train.loc[:, test.columns != \"label\"].to_numpy()\n",
    "test_matrix = test.loc[:, test.columns != \"label\"].to_numpy()\n",
    "\n",
    "print(train_matrix)\n",
    "print(test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components =4).fit(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = gmm.score_samples(test_matrix)\n",
    "print(score)\n",
    "\n",
    "auc = roc_auc_score(test[\"label\"], score)\n",
    "print(f\"area under the curve: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_threshold = np.percentile(score, 50)\n",
    "print(pct_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = pct_threshold\n",
    "labels = [1 if x > threshold else 0 for x in score]\n",
    "correct = 0\n",
    "\n",
    "for i, x in test.iterrows():\n",
    "    # print(x)\n",
    "    try:\n",
    "        if x[\"label\"] == labels[i]:\n",
    "            correct += 1\n",
    "    except:\n",
    "        print(i)\n",
    "        print(x)\n",
    "\n",
    "print(f\"accuracy with threshold {threshold}: {correct / len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanstd([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# import random\n",
    "import numpy as np\n",
    "l = [\"aa\", \"b\", \"c\"]\n",
    "\n",
    "a = np.array(list(itertools.combinations(l, 2)))\n",
    "np.random.shuffle(a)\n",
    "# a = [x for x in a]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"| Authorized   |      Unauthorized      |  AUC |\\n\"\n",
    "table += \"| ------------- |:-------------:| -----:|\\n\"\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = DataFrame({\"a\": [1, 2, 3, 4, 5], \"b\": [4, 5, 6, 7, 8]})\n",
    "\n",
    "print(len(asdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects: dict[str, DataFrame] = SubjectSelectorList(join(pathlib.Path().resolve(), \"data\\\\me_time_fused\\\\subjects\"), ['1', '2'], True, True).get_subjects()\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects: dict[str, DataFrame] = SubjectSelectorList(join(pathlib.Path().resolve(), \"data\\\\me_time_fused\\\\subjects\"),['1', '2'], True, True).get_subjects()\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestSplitter = TrainTestSplitterRawData(1, 0.8)\n",
    "train, test = trainTestSplitter.splitBeforeWindowing(subjects)\n",
    "auth, unauth = trainTestSplitter.getAuthAndUnauthIds()\n",
    "\n",
    "print(auth)\n",
    "print(unauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = \\\n",
    "#     WindowSplitterNoOverlap(windowSize = 720, \\\n",
    "#                             hrTransformations = [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax], \\\n",
    "#                             stepTransformations = [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax]).split(train)\n",
    "# test = \\\n",
    "#     WindowSplitterNoOverlap(windowSize = 720, \\\n",
    "#                             hrTransformations = [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax], \\\n",
    "#                             stepTransformations = [np.nanmean, np.nanstd, np.nanmedian, np.nanvar, np.nanmin, np.nanmax]).split(test)\n",
    "\n",
    "train = \\\n",
    "    WindowSplitterNoOverlap(windowSize = 720, \\\n",
    "                            hrTransformations = [np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)], \\\n",
    "                            stepTransformations = [np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)]).split(train)\n",
    "test = \\\n",
    "    WindowSplitterNoOverlap(windowSize = 720, \\\n",
    "                            hrTransformations = [np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)], \\\n",
    "                            stepTransformations = [np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)]).split(test)\n",
    "\n",
    "train = pd.concat(train.values())\n",
    "test = pd.concat(test.values())\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_matrix = train.loc[:, test.columns != \"label\"].to_numpy()\n",
    "test_matrix = test.loc[:, test.columns != \"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "\n",
    "    ax.axis('equal')\n",
    "\n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components =4).fit(train_matrix)\n",
    "# plot_gmm(gmm, train_matrix)\n",
    "# print(gmm.means_)\n",
    "# print(gmm.covariances_)\n",
    "# print(gmm.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score = gmm.score_samples(test_matrix)\n",
    "        \n",
    "auc = roc_auc_score(test[\"label\"], score)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'a', 'a'],\n",
    "                   'B' : [1, 2, 3, 4, 5, 2, 3],\n",
    "                   'C' : [2.0, 5., 8., 1., 2., 2., 3.]})\n",
    "\n",
    "df.groupby('A').filter(lambda x: len(x) == 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\n",
    "    \"a\": 1,\n",
    "    \"b\": 2,\n",
    "    \"c\": 3\n",
    "}\n",
    "\n",
    "print(type(a))\n",
    "print('c' in a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "np.random.seed(0)\n",
    "C = np.array([[0.0, -0.1], [1.7, 0.4]])\n",
    "component_1 = np.dot(np.random.randn(n_samples, 2), C)  # general\n",
    "component_2 = 0.7 * np.random.randn(n_samples, 2) + np.array([-4, 1])  # spherical\n",
    "\n",
    "X = np.concatenate([component_1, component_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(component_1[:, 0], component_1[:, 1], s=0.8)\n",
    "plt.scatter(component_2[:, 0], component_2[:, 1], s=0.8)\n",
    "plt.title(\"Gaussian Mixture components\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_bic_score(estimator, X):\n",
    "    \"\"\"Callable to pass to GridSearchCV that will use the BIC score.\"\"\"\n",
    "    # Make it negative since GridSearchCV expects a score to maximize\n",
    "    return -estimator.bic(X)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_components\": range(1, 7),\n",
    "    \"covariance_type\": [\"spherical\", \"tied\", \"diag\", \"full\"],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    GaussianMixture(), param_grid=param_grid, scoring=gmm_bic_score, n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid_search.cv_results_)[\n",
    "    [\"param_n_components\", \"param_covariance_type\", \"mean_test_score\"]\n",
    "]\n",
    "df[\"mean_test_score\"] = -df[\"mean_test_score\"]\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"param_n_components\": \"Number of components\",\n",
    "        \"param_covariance_type\": \"Type of covariance\",\n",
    "        \"mean_test_score\": \"BIC score\",\n",
    "    }\n",
    ")\n",
    "df.sort_values(by=\"BIC score\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectsPath = join(pathlib.Path().resolve(), \"data\\\\me_time_fused\\\\subjects\")\n",
    "subjects: dict[str, DataFrame] = SubjectSelectorList(subjectsPath,['1', '2'], True, False).get_subjects()\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestSplitter = TrainTestSplitterRawData(1, 0.8, auth = ['1'], nonAuth = ['2'])\n",
    "train, test = trainTestSplitter.splitBeforeWindowing(subjects)\n",
    "auth, unauth = trainTestSplitter.getAuthAndUnauthIds()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupSplitterPerTimeframe(data: DataFrame) -> np.array:\n",
    "    # print(data[\"time\"])\n",
    "    first = pd.to_datetime(np.array(data[\"time\"])[0])\n",
    "    return np.array(data[\"time\"].dt.hour // 6 + (data[\"time\"] - first).dt.days * 4)\n",
    "\n",
    "def groupSplitterPerHour(data: DataFrame) -> np.array:\n",
    "    first = pd.to_datetime(np.array(data[\"time\"])[0])\n",
    "    return np.array(data[\"time\"].dt.hour + (data[\"time\"] - first).dt.days * 24)\n",
    "\n",
    "def gmm_bic_score(estimator, X):\n",
    "    \"\"\"Callable to pass to GridSearchCV that will use the BIC score.\"\"\"\n",
    "    # Make it negative since GridSearchCV expects a score to maximize\n",
    "    return -estimator.bic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"imputer\", WindowedImputer(hrTransformations = [np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)], groupFunction=groupSplitterPerHour)), (\"gmm\", GaussianMixture(n_components=4))])\n",
    "train2 = pipe.fit_predict(train)\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"imputer\", WindowedImputer()), (\"gmm\", GaussianMixture())])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"imputer__hrTransformations\": [[np.nanmean, np.nanmedian, np.nanvar, lambda x: np.nanmax(x) - np.nanmin(x)]],\n",
    "    \"imputer__stepTransformations\": [None],\n",
    "    \"imputer__groupFunction\": [groupSplitterPerHour],\n",
    "    \"gmm__n_components\": [4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid=param_grid, scoring=gmm_bic_score\n",
    ")\n",
    "\n",
    "grid_search.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
